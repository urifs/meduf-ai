"""
Medical Image Analysis Engine with Vision
Uses Gemini 2.5 Flash for direct image analysis (supports vision)
Supports: Lab exams only
"""
import os
import base64
import io
from typing import Dict, Any, Optional
from emergentintegrations.llm.chat import LlmChat, UserMessage, FileContent
from PIL import Image
import pytesseract
import json

# Get Emergent Universal Key from environment
EMERGENT_KEY = os.environ.get("EMERGENT_LLM_KEY", "sk-emergent-b51Fb1fC8C81f9e13D")


def extract_text_from_image(image_data: str) -> str:
    """
    Extract text from image using OCR (fallback)
    """
    try:
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        text = pytesseract.image_to_string(image, lang='por+eng')
        return text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è OCR Error: {e}")
        return ""


async def analyze_exam_image(image_data: str, image_type: str, additional_info: str = "") -> Dict[str, Any]:
    """
    Analyze medical exam images (laboratory results) using Gemini 2.5 Flash with vision
    """
    try:
        print("üîç Iniciando an√°lise de exame com Gemini 2.5 Flash (Vision)...")
        
        # Prepare image data
        if image_type.startswith('image/'):
            # Use image directly for vision model
            image_base64 = image_data
            print("üì∏ Usando an√°lise visual direta com Gemini 2.5 Flash")
        else:
            # For non-images, use OCR
            print("üìÑ Extraindo texto com OCR...")
            image_base64 = None
            extracted_text = image_data
        
        # Create system prompt for lab exam analysis
        system_prompt = """Voc√™ √© um m√©dico especializado em an√°lise de exames laboratoriais.

Analise a IMAGEM do exame fornecido e identifique:

1. **Tipo de Exame** - Identifique qual(is) exame(s) est√°(√£o) presente(s)
2. **Valores Alterados** - Liste TODOS os par√¢metros fora dos valores de refer√™ncia
3. **An√°lise Cl√≠nica** - Interprete o significado cl√≠nico das altera√ß√µes
4. **Gravidade** - Classifique a gravidade das altera√ß√µes (Leve/Moderada/Grave)
5. **Recomenda√ß√µes** - Sugira condutas, exames complementares ou avalia√ß√µes necess√°rias

**IMPORTANTE:**
- Leia TODOS os valores vis√≠veis na imagem
- Seja preciso e t√©cnico
- Destaque valores cr√≠ticos ou muito alterados
- Use terminologia m√©dica brasileira
- Indique se h√° necessidade de avalia√ß√£o urgente
- Compare com valores de refer√™ncia quando dispon√≠veis no exame

**FORMATO DA RESPOSTA (APENAS JSON, SEM TEXTO EXTRA):**
```json
{
  "exam_type": "Tipo do exame identificado",
  "altered_values": [
    {
      "parameter": "Nome do par√¢metro",
      "value": "Valor encontrado",
      "reference": "Valor de refer√™ncia",
      "status": "Aumentado/Diminu√≠do",
      "severity": "Leve/Moderada/Grave"
    }
  ],
  "clinical_interpretation": "Interpreta√ß√£o cl√≠nica detalhada das altera√ß√µes",
  "overall_severity": "Leve/Moderada/Grave/Normal",
  "recommendations": [
    "Recomenda√ß√£o 1",
    "Recomenda√ß√£o 2"
  ],
  "urgent_attention": true/false,
  "additional_notes": "Observa√ß√µes adicionais importantes"
}
```"""

        # Build user prompt
        additional_context = ""
        if additional_info:
            additional_context = f"\n\n**Informa√ß√µes Adicionais do Paciente:**\n{additional_info}"
        
        if image_base64:
            user_prompt = f"""Analise a IMAGEM do exame laboratorial fornecido.
{additional_context}

Por favor, leia todos os valores vis√≠veis na imagem e forne√ßa uma an√°lise completa em formato JSON identificando todas as altera√ß√µes e sua relev√¢ncia cl√≠nica."""
        else:
            user_prompt = f"""Analise o seguinte texto de exame laboratorial:

**TEXTO DO EXAME:**
{extracted_text}
{additional_context}

Por favor, forne√ßa uma an√°lise completa em formato JSON."""

        print("ü§ñ Enviando para Gemini 2.5 Flash com suporte a vis√£o...")
        
        # Create chat with Gemini 2.5 Flash (supports vision)
        chat = LlmChat(
            api_key=EMERGENT_KEY,
            session_id="meduf-exam-vision",
            system_message=system_prompt
        ).with_model("gemini", "gemini-2.5-flash")

        # Send message with image if available
        if image_base64:
            # Send with image using FileContent
            file_content = FileContent(
                content_type=image_type,
                file_content_base64=image_base64
            )
            message = UserMessage(
                text=user_prompt,
                file_contents=[file_content]
            )
        else:
            # Send text only
            message = UserMessage(text=user_prompt)

        response = await chat.send_message(message)
        
        print("üìä Resposta recebida do Gemini, processando...")
        
        # Parse JSON response
        response_text = response.strip() if isinstance(response, str) else str(response)
        
        # Extract JSON from markdown code blocks
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        try:
            analysis = json.loads(response_text)
            print("‚úÖ An√°lise conclu√≠da com sucesso!")
            return analysis
        except json.JSONDecodeError:
            print("‚ö†Ô∏è Resposta n√£o estruturada, retornando como texto")
            return {
                "exam_type": "Exame Laboratorial",
                "altered_values": [],
                "clinical_interpretation": response_text,
                "overall_severity": "Avaliar",
                "recommendations": ["Consulte um m√©dico para interpreta√ß√£o completa"],
                "urgent_attention": False,
                "additional_notes": "Resposta em formato texto - an√°lise manual recomendada"
            }
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        import traceback
        traceback.print_exc()
        
        # Try fallback with OCR if image analysis failed
        if image_type.startswith('image/'):
            print("üîÑ Tentando fallback com OCR...")
            try:
                extracted_text = extract_text_from_image(image_data)
                if extracted_text:
                    print("üìù OCR bem-sucedido, reprocessando...")
                    # Retry with extracted text
                    return await analyze_exam_image(extracted_text, "text/plain", additional_info)
            except:
                pass
        
        return {
            "exam_type": "Erro na An√°lise",
            "altered_values": [],
            "clinical_interpretation": f"Ocorreu um erro ao processar o exame: {str(e)}",
            "overall_severity": "Indeterminada",
            "recommendations": [
                "Tente fazer o upload novamente",
                "Verifique se a imagem est√° leg√≠vel",
                "Tire uma foto mais clara e bem iluminada",
                "Consulte um m√©dico para an√°lise presencial"
            ],
            "urgent_attention": False,
            "additional_notes": f"Erro t√©cnico: {str(e)}"
        }



async def analyze_multiple_exam_images(files_data: list, additional_info: str = "", user_id: str = None, user_name: str = None) -> Dict[str, Any]:
    """
    Analyze multiple exam images (for multi-page exams)
    Combines all pages into a single comprehensive analysis
    """
    try:
        print(f"üîç Analisando {len(files_data)} p√°ginas de exame...")
        
        if len(files_data) == 1:
            # Single file - use regular analysis
            return await analyze_exam_image(
                files_data[0]['data'],
                files_data[0]['type'],
                additional_info
            )
        
        # Multiple files - combine all images/text
        all_text = []
        all_images_base64 = []
        
        for idx, file_data in enumerate(files_data):
            print(f"  Processando p√°gina {idx + 1}/{len(files_data)}")
            
            if file_data['type'].startswith('image/'):
                all_images_base64.append({
                    'data': file_data['data'],
                    'type': file_data['type'],
                    'page': idx + 1
                })
            else:
                # Text content
                all_text.append(f"--- P√°gina {idx + 1} ---\n{file_data['data']}\n")
        
        # If we have images, analyze them with Gemini 2.5 Flash
        if all_images_base64:
            print(f"üì∏ Analisando {len(all_images_base64)} imagens com Gemini 2.5 Flash")
            
            # Build comprehensive prompt
            system_prompt = """Voc√™ √© um m√©dico especializado em an√°lise de exames laboratoriais.

Voc√™ receber√° M√öLTIPLAS P√ÅGINAS de um mesmo exame ou de exames relacionados.

Analise TODAS as p√°ginas fornecidas e:

1. **Tipo de Exame(s)** - Identifique todos os exames presentes em todas as p√°ginas
2. **Valores Alterados** - Liste TODOS os par√¢metros fora dos valores de refer√™ncia de TODAS as p√°ginas
3. **An√°lise Cl√≠nica Integrada** - Interprete o significado cl√≠nico combinado de todas as altera√ß√µes
4. **Gravidade Geral** - Classifique considerando todos os achados
5. **Recomenda√ß√µes Consolidadas** - Sugira condutas baseadas em todas as informa√ß√µes

**IMPORTANTE:**
- Analise TODAS as p√°ginas fornecidas
- Integre os achados de todas as p√°ginas
- Se houver p√°ginas duplicadas, considere apenas uma vez
- Seja preciso e t√©cnico
- Use terminologia m√©dica brasileira

**FORMATO DA RESPOSTA (APENAS JSON, SEM TEXTO EXTRA):**
```json
{
  "exam_type": "Tipo(s) do(s) exame(s) identificado(s) em todas as p√°ginas",
  "pages_analyzed": 2,
  "altered_values": [
    {
      "parameter": "Nome do par√¢metro",
      "value": "Valor encontrado",
      "reference": "Valor de refer√™ncia",
      "status": "Aumentado/Diminu√≠do",
      "severity": "Leve/Moderada/Grave",
      "page": 1
    }
  ],
  "clinical_interpretation": "Interpreta√ß√£o cl√≠nica integrada de todas as p√°ginas",
  "overall_severity": "Leve/Moderada/Grave/Normal",
  "recommendations": ["Recomenda√ß√£o 1", "Recomenda√ß√£o 2"],
  "urgent_attention": true/false,
  "additional_notes": "Observa√ß√µes sobre o exame completo"
}
```"""

            additional_context = ""
            if additional_info:
                additional_context = f"\n\n**Informa√ß√µes Adicionais do Paciente:**\n{additional_info}"
            
            user_prompt = f"""Analise TODAS as {len(all_images_base64)} p√°ginas do exame laboratorial fornecidas.
{additional_context}

Por favor, forne√ßa uma an√°lise INTEGRADA em formato JSON considerando TODAS as p√°ginas."""

            print("ü§ñ Enviando para Gemini 2.5 Flash com vis√£o...")
            
            # Create chat with Gemini 2.5 Flash
            chat = LlmChat(
                api_key=EMERGENT_KEY,
                session_id="meduf-exam-multi-vision",
                system_message=system_prompt
            ).with_model("gemini", "gemini-2.5-flash")

            # Create FileContent for all images
            file_contents = []
            for img_data in all_images_base64:
                file_content = FileContent(
                    content_type=img_data['type'],
                    file_content_base64=img_data['data']
                )
                file_contents.append(file_content)
            
            # Send message with all images
            message = UserMessage(
                text=user_prompt,
                file_contents=file_contents
            )

            response = await chat.send_message(message)
            
            print("üìä Resposta recebida, processando...")
            
            # Parse JSON response
            response_text = response.strip() if isinstance(response, str) else str(response)
            
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()
            
            try:
                analysis = json.loads(response_text)
                analysis['pages_analyzed'] = len(files_data)
                print(f"‚úÖ An√°lise de {len(files_data)} p√°ginas conclu√≠da!")
                return analysis
            except json.JSONDecodeError:
                print("‚ö†Ô∏è Resposta n√£o estruturada")
                return {
                    "exam_type": f"Exame Laboratorial ({len(files_data)} p√°ginas)",
                    "pages_analyzed": len(files_data),
                    "altered_values": [],
                    "clinical_interpretation": response_text,
                    "overall_severity": "Avaliar",
                    "recommendations": ["Consulte um m√©dico para interpreta√ß√£o completa"],
                    "urgent_attention": False,
                    "additional_notes": "Resposta em formato texto"
                }
        
        else:
            # Text only - combine and analyze
            combined_text = "\n\n".join(all_text)
            return await analyze_exam_image(combined_text, "text/plain", additional_info)
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de m√∫ltiplas p√°ginas: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "exam_type": f"Erro na An√°lise ({len(files_data)} p√°ginas)",
            "pages_analyzed": len(files_data),
            "altered_values": [],
            "clinical_interpretation": f"Erro ao processar {len(files_data)} p√°ginas: {str(e)}",
            "overall_severity": "Indeterminada",
            "recommendations": [
                "Tente fazer o upload novamente",
                "Verifique se todas as imagens est√£o leg√≠veis",
                "Consulte um m√©dico para an√°lise presencial"
            ],
            "urgent_attention": False,
            "additional_notes": f"Erro t√©cnico: {str(e)}"
        }
