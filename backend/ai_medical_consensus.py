"""
AI Medical Consensus Engine
Uses 3 LLMs (GPT-5, Claude Sonnet 4, Gemini 2.0) + PubMed research
Returns consensus diagnosis based on multiple AI opinions
"""
import os
import asyncio
from typing import Dict, List, Any, Optional
from emergentintegrations.llm.chat import LlmChat, UserMessage
import aiohttp
import xml.etree.ElementTree as ET


# Get Emergent Universal Key from environment
EMERGENT_KEY = os.environ.get("EMERGENT_LLM_KEY", "sk-emergent-b51Fb1fC8C81f9e13D")


MEDICAL_SYSTEM_PROMPT = """Voc√™ √© um assistente cl√≠nico especializado. Analise os sintomas fornecidos e forne√ßa:

1. **Diagn√≥sticos Diferenciais** (3-5 hip√≥teses mais prov√°veis)
2. **Justificativas Cl√≠nicas** para cada diagn√≥stico
3. **Conduta Inicial** (exames e procedimentos)
4. **Medica√ß√µes Sugeridas** (com doses e mecanismos)

**IMPORTANTE:**
- Seja preciso e t√©cnico
- Use terminologia m√©dica brasileira
- Baseie-se em evid√™ncias cient√≠ficas
- Considere diagn√≥sticos diferenciais importantes
- Sugira exames complementares relevantes
- N√ÉO substitui consulta m√©dica presencial

**ESTRUTURA DA RESPOSTA:**
```json
{
  "diagnoses": [
    {
      "name": "Nome do Diagn√≥stico",
      "justification": "Justificativa cl√≠nica detalhada"
    }
  ],
  "conduct": {
    "advice": "Conduta geral e recomenda√ß√µes",
    "procedures": ["Procedimento 1", "Procedimento 2"]
  },
  "medications": [
    {
      "name": "Nome do medicamento",
      "dosage": "Dose e via de administra√ß√£o",
      "mechanism": "Mecanismo de a√ß√£o"
    }
  ]
}
```
"""


async def search_pubmed(query: str, max_results: int = 5) -> List[Dict[str, str]]:
    """
    Search PubMed for medical literature related to the query
    Returns list of relevant articles with titles and abstracts
    """
    try:
        # PubMed E-utilities API
        base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        
        # Search for articles
        search_url = f"{base_url}esearch.fcgi"
        search_params = {
            "db": "pubmed",
            "term": query,
            "retmax": max_results,
            "retmode": "json",
            "sort": "relevance"
        }
        
        async with aiohttp.ClientSession() as session:
            # Get article IDs
            async with session.get(search_url, params=search_params) as response:
                if response.status != 200:
                    return []
                search_data = await response.json()
                
            id_list = search_data.get("esearchresult", {}).get("idlist", [])
            
            if not id_list:
                return []
            
            # Fetch article details
            fetch_url = f"{base_url}efetch.fcgi"
            fetch_params = {
                "db": "pubmed",
                "id": ",".join(id_list),
                "retmode": "xml"
            }
            
            async with session.get(fetch_url, params=fetch_params) as response:
                if response.status != 200:
                    return []
                xml_data = await response.text()
            
            # Parse XML
            root = ET.fromstring(xml_data)
            articles = []
            
            for article in root.findall(".//PubmedArticle"):
                try:
                    title_elem = article.find(".//ArticleTitle")
                    abstract_elem = article.find(".//AbstractText")
                    
                    title = title_elem.text if title_elem is not None else "Sem t√≠tulo"
                    abstract = abstract_elem.text if abstract_elem is not None else "Sem resumo dispon√≠vel"
                    
                    articles.append({
                        "title": title,
                        "abstract": abstract[:500]  # Limit abstract length
                    })
                except Exception as e:
                    continue
            
            return articles[:max_results]
            
    except Exception as e:
        print(f"PubMed search error: {e}")
        return []


async def get_ai_diagnosis(
    provider: str,
    model: str,
    patient_data: Dict[str, Any],
    pubmed_context: str = ""
) -> Optional[Dict[str, Any]]:
    """
    Get diagnosis from a single AI provider
    """
    try:
        # Create chat instance
        chat = LlmChat(
            api_key=EMERGENT_KEY,
            session_id=f"meduf-{provider}-{patient_data.get('queixa', 'unknown')[:20]}",
            system_message=MEDICAL_SYSTEM_PROMPT
        ).with_model(provider, model)
        
        # Build prompt
        prompt = f"""**DADOS DO PACIENTE:**
- Idade: {patient_data.get('idade', 'N/I')}
- Sexo: {patient_data.get('sexo', 'N/I')}
- Queixa Principal: {patient_data.get('queixa', 'N√£o informada')}
- Hist√≥ria Cl√≠nica: {patient_data.get('historia', 'N√£o informada')}
- Exame F√≠sico: {patient_data.get('exame_fisico', 'N√£o informado')}
- Exames Complementares: {patient_data.get('exames', 'N√£o informados')}

{pubmed_context}

**Forne√ßa sua an√°lise cl√≠nica em formato JSON conforme especificado.**
"""
        
        message = UserMessage(text=prompt)
        response = await chat.send_message(message)
        
        # Try to parse JSON response
        import json
        
        # Extract JSON from markdown code blocks if present
        response_text = response.strip()
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        diagnosis = json.loads(response_text)
        diagnosis["provider"] = provider
        return diagnosis
        
    except Exception as e:
        print(f"Error with {provider}: {e}")
        return None


async def create_consensus_diagnosis(
    diagnoses: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    Create consensus diagnosis from multiple AI responses
    Combines and weights the most common diagnoses
    """
    if not diagnoses:
        return {
            "diagnoses": [{"name": "Erro ao processar", "justification": "N√£o foi poss√≠vel obter diagn√≥sticos das IAs"}],
            "conduct": {"advice": "Consulte um m√©dico presencialmente", "procedures": []},
            "medications": []
        }
    
    # Count diagnosis frequency
    diagnosis_count = {}
    all_diagnoses = []
    all_medications = []
    all_procedures = []
    all_advice = []
    
    for ai_response in diagnoses:
        provider = ai_response.get("provider", "unknown")
        
        # Collect diagnoses
        for diag in ai_response.get("diagnoses", []):
            name = diag.get("name", "").lower()
            if name:
                if name not in diagnosis_count:
                    diagnosis_count[name] = {
                        "count": 0,
                        "justifications": [],
                        "original_name": diag.get("name")
                    }
                diagnosis_count[name]["count"] += 1
                justification = diag.get('justification', '')
                if justification:
                    diagnosis_count[name]["justifications"].append(justification)
        
        # Collect medications
        for med in ai_response.get("medications", []):
            if med not in all_medications:
                all_medications.append(med)
        
        # Collect procedures
        conduct = ai_response.get("conduct", {})
        for proc in conduct.get("procedures", []):
            if proc not in all_procedures:
                all_procedures.append(proc)
        
        # Collect advice
        advice = conduct.get("advice", "")
        if advice:
            all_advice.append(advice)
    
    # Sort diagnoses by frequency
    sorted_diagnoses = sorted(
        diagnosis_count.items(),
        key=lambda x: x[1]["count"],
        reverse=True
    )
    
    # Build consensus response
    consensus_diagnoses = []
    for name, data in sorted_diagnoses[:5]:  # Top 5 diagnoses
        # Combine justifications without AI labels
        combined_justification = " ".join(data["justifications"][:2])
        consensus_diagnoses.append({
            "name": data["original_name"],
            "justification": combined_justification,
            "ai_agreement": f"{data['count']}/2 IAs"
        })
    
    return {
        "diagnoses": consensus_diagnoses,
        "conduct": {
            "advice": "\n\n".join(all_advice[:2]),  # Top 2 advice
            "procedures": all_procedures[:8]  # Top 8 procedures
        },
        "medications": all_medications[:6]  # Top 6 medications
    }


async def get_ai_consensus_diagnosis(patient_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Main function: Get consensus diagnosis from 3 AIs
    """
    try:
        # Query 2 AIs in parallel
        print("ü§ñ Querying AIs in parallel...")
        tasks = [
            get_ai_diagnosis("anthropic", "claude-sonnet-4-20250514", patient_data, ""),
            get_ai_diagnosis("gemini", "gemini-2.0-flash", patient_data, "")
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter out errors and None values
        valid_diagnoses = [r for r in results if r and not isinstance(r, Exception)]
        
        print(f"‚úÖ Got {len(valid_diagnoses)}/2 AI responses")
        
        # Create consensus
        print("üß† Creating consensus...")
        consensus = await create_consensus_diagnosis(valid_diagnoses)
        
        return consensus
        
    except Exception as e:
        print(f"‚ö†Ô∏è Consensus engine error: {e}")
        import traceback
        traceback.print_exc()
        
        # Return meaningful fallback based on symptoms
        queixa = patient_data.get("queixa", "").lower()
        
        fallback_diagnoses = [
            {
                "name": "An√°lise Parcial - Avalia√ß√£o M√©dica Recomendada",
                "justification": "N√£o foi poss√≠vel completar a an√°lise automatizada completa. Recomenda-se avalia√ß√£o m√©dica presencial para exame f√≠sico e anamnese detalhada.",
                "ai_agreement": "1/2"
            }
        ]
        
        # Add basic symptom-based suggestion
        if "febre" in queixa:
            fallback_diagnoses.append({
                "name": "S√≠ndrome Febril a Esclarecer",
                "justification": "Presen√ßa de febre requer investiga√ß√£o para identificar foco infeccioso. Exame f√≠sico completo e exames complementares s√£o necess√°rios.",
                "ai_agreement": "1/2"
            })
        elif "dor" in queixa:
            fallback_diagnoses.append({
                "name": "S√≠ndrome √Ålgica a Investigar",
                "justification": "Quadro de dor requer avalia√ß√£o cl√≠nica para caracteriza√ß√£o e investiga√ß√£o da causa.",
                "ai_agreement": "1/2"
            })
        
        return {
            "diagnoses": fallback_diagnoses,
            "conduct": {
                "advice": "Consulta m√©dica presencial recomendada para avalia√ß√£o completa, exame f√≠sico e defini√ß√£o de conduta.",
                "procedures": ["Avalia√ß√£o m√©dica presencial", "Exame f√≠sico completo", "Anamnese detalhada"]
            },
            "medications": []
        }



async def get_ai_consensus_medication_guide(symptoms: str) -> Dict[str, Any]:
    """
    Get medication recommendations using 3 AIs
    """
    try:
        # Create prompt for medication recommendations
        medication_prompt = f"""**SINTOMAS DO PACIENTE:**
{symptoms}

**Forne√ßa recomenda√ß√µes de medicamentos em formato JSON:**
```json
{{
  "medications": [
    {{
      "name": "Nome do medicamento",
      "dose": "Dose recomendada",
      "frequency": "Frequ√™ncia",
      "notes": "Observa√ß√µes cl√≠nicas",
      "contraindications": "Contraindica√ß√µes principais"
    }}
  ]
}}
```
"""
        
        # Query 2 AIs
        tasks = []
        for provider, model in [
            ("anthropic", "claude-sonnet-4-20250514"),
            ("gemini", "gemini-2.0-flash")
        ]:
            chat = LlmChat(
                api_key=EMERGENT_KEY,
                session_id=f"meduf-med-{provider}",
                system_message="Voc√™ √© um farmac√™utico cl√≠nico especializado. Recomende medicamentos baseados em evid√™ncias cient√≠ficas."
            ).with_model(provider, model)
            tasks.append(chat.send_message(UserMessage(text=medication_prompt)))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Parse responses
        all_medications = []
        for i, response in enumerate(results):
            if isinstance(response, Exception):
                continue
            try:
                import json
                response_text = response.strip()
                if "```json" in response_text:
                    response_text = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    response_text = response_text.split("```")[1].split("```")[0].strip()
                
                data = json.loads(response_text)
                for med in data.get("medications", []):
                    if med not in all_medications:
                        all_medications.append(med)
            except:
                continue
        
        return {"medications": all_medications[:8]}  # Top 8
        
    except Exception as e:
        print(f"‚ö†Ô∏è Medication guide error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "medications": [
                {
                    "name": "Consulta M√©dica Necess√°ria",
                    "dose": "N/A",
                    "frequency": "N/A",
                    "route": "Presencial",
                    "notes": "N√£o foi poss√≠vel gerar recomenda√ß√µes automatizadas. Consulte um m√©dico ou farmac√™utico para orienta√ß√µes personalizadas sobre medicamentos adequados aos seus sintomas."
                }
            ]
        }


async def get_ai_consensus_drug_interaction(drug1: str, drug2: str) -> Dict[str, Any]:
    """
    Analyze drug interaction using 3 AIs
    """
    try:
        interaction_prompt = f"""**AN√ÅLISE DE INTERA√á√ÉO MEDICAMENTOSA:**
Medicamento 1: {drug1}
Medicamento 2: {drug2}

**Forne√ßa an√°lise completa em formato JSON:**
```json
{{
  "severity": "GRAVE/MODERADA/BAIXA",
  "summary": "Resumo da intera√ß√£o",
  "details": "Detalhes farmacocin√©ticos e farmacodin√¢micos",
  "recommendations": "Recomenda√ß√µes cl√≠nicas",
  "renal_impact": "Impacto renal de ambos os medicamentos",
  "hepatic_impact": "Impacto hep√°tico de ambos os medicamentos"
}}
```
"""
        
        # Query 2 AIs
        tasks = []
        for provider, model in [
            ("anthropic", "claude-sonnet-4-20250514"),
            ("gemini", "gemini-2.0-flash")
        ]:
            chat = LlmChat(
                api_key=EMERGENT_KEY,
                session_id=f"meduf-interaction-{provider}",
                system_message="Voc√™ √© um farmacologista especializado em intera√ß√µes medicamentosas. Baseie suas respostas em evid√™ncias cient√≠ficas."
            ).with_model(provider, model)
            tasks.append(chat.send_message(UserMessage(text=interaction_prompt)))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Parse and create consensus
        valid_responses = []
        for response in results:
            if isinstance(response, Exception):
                continue
            try:
                import json
                response_text = response.strip()
                if "```json" in response_text:
                    response_text = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    response_text = response_text.split("```")[1].split("```")[0].strip()
                
                data = json.loads(response_text)
                valid_responses.append(data)
            except:
                continue
        
        if not valid_responses:
            return {
                "severity": "DESCONHECIDA",
                "summary": "N√£o foi poss√≠vel analisar a intera√ß√£o",
                "details": "Erro ao processar dados das IAs",
                "recommendations": "Consulte um farmac√™utico ou m√©dico",
                "renal_impact": "N√£o dispon√≠vel",
                "hepatic_impact": "N√£o dispon√≠vel"
            }
        
        # Get most common severity
        severities = [r.get("severity", "").upper() for r in valid_responses]
        severity_counts = {}
        for s in severities:
            if "GRAVE" in s:
                severity_counts["GRAVE"] = severity_counts.get("GRAVE", 0) + 1
            elif "MODERADA" in s:
                severity_counts["MODERADA"] = severity_counts.get("MODERADA", 0) + 1
            else:
                severity_counts["BAIXA"] = severity_counts.get("BAIXA", 0) + 1
        
        consensus_severity = max(severity_counts.items(), key=lambda x: x[1])[0]
        
        # Combine details
        return {
            "severity": consensus_severity,
            "summary": valid_responses[0].get("summary", ""),
            "details": "\n\n".join([r.get('details', '') for r in valid_responses[:2]]),
            "recommendations": "\n\n".join([r.get('recommendations', '') for r in valid_responses[:2]]),
            "renal_impact": valid_responses[0].get("renal_impact", "N√£o dispon√≠vel"),
            "hepatic_impact": valid_responses[0].get("hepatic_impact", "N√£o dispon√≠vel"),
            "monitoring": {
                "renal": ["Creatinina s√©rica", "TFG (Taxa de Filtra√ß√£o Glomerular)"],
                "hepatic": ["TGO/TGP (Transaminases)", "Bilirrubinas"],
                "outros": ["Conforme recomenda√ß√£o m√©dica"]
            }
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Drug interaction consensus error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "severity": "An√°lise Incompleta",
            "summary": f"N√£o foi poss√≠vel completar an√°lise de intera√ß√£o. Consulte profissional.",
            "details": "Sempre consulte um profissional antes de combinar medicamentos.",
            "recommendations": "‚Ä¢ Consulte farmac√™utico ou m√©dico",
            "renal_impact": "Avalia√ß√£o profissional necess√°ria",
            "hepatic_impact": "Avalia√ß√£o profissional necess√°ria"
        }


async def get_ai_consensus_toxicology(substance: str) -> Dict[str, Any]:
    """
    Get toxicology protocol using 3 AIs
    """
    try:
        toxicology_prompt = f"""**AN√ÅLISE TOXICOL√ìGICA:**
Subst√¢ncia: {substance}

**Forne√ßa protocolo toxicol√≥gico em formato JSON:**
```json
{{
  "agent": "Nome do agente t√≥xico identificado",
  "antidote": "Ant√≠doto espec√≠fico",
  "mechanism": "Mecanismo de toxicidade",
  "conduct": ["Conduta 1", "Conduta 2", "Conduta 3"],
  "protocol": "Protocolo de tratamento detalhado"
}}
```
"""
        
        # Query 2 AIs
        tasks = []
        for provider, model in [
            ("anthropic", "claude-sonnet-4-20250514"),
            ("gemini", "gemini-2.0-flash")
        ]:
            chat = LlmChat(
                api_key=EMERGENT_KEY,
                session_id=f"meduf-tox-{provider}",
                system_message="Voc√™ √© um toxicologista cl√≠nico especializado. Forne√ßa protocolos baseados em diretrizes internacionais."
            ).with_model(provider, model)
            tasks.append(chat.send_message(UserMessage(text=toxicology_prompt)))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Parse and create consensus
        valid_responses = []
        for response in results:
            if isinstance(response, Exception):
                continue
            try:
                import json
                response_text = response.strip()
                if "```json" in response_text:
                    response_text = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    response_text = response_text.split("```")[1].split("```")[0].strip()
                
                data = json.loads(response_text)
                valid_responses.append(data)
            except:
                continue
        
        if not valid_responses:
            return {
                "agent": "Agente Desconhecido",
                "antidote": "Suporte cl√≠nico (ABCDE)",
                "mechanism": "N√£o foi poss√≠vel determinar",
                "conduct": ["Estabiliza√ß√£o", "Suporte ventilat√≥rio", "Monitoriza√ß√£o"],
                "protocol": "Protocolo b√°sico de suporte"
            }
        
        # Combine the best responses
        all_conduct = []
        for r in valid_responses:
            all_conduct.extend(r.get("conduct", []))
        
        return {
            "agent": valid_responses[0].get("agent", "Agente n√£o identificado"),
            "antidote": valid_responses[0].get("antidote", "Suporte cl√≠nico"),
            "mechanism": valid_responses[0].get("mechanism", ""),
            "conduct": list(set(all_conduct))[:6],  # Unique, top 6
            "protocol": "\n\n".join([r.get('protocol', '') for r in valid_responses[:2]])
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Toxicology consensus error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "agent": f"Intoxica√ß√£o por {substance}",
            "antidote": "Consultar protocolo espec√≠fico e Centro de Toxicologia",
            "mechanism": "Avalia√ß√£o toxicol√≥gica completa necess√°ria. Mecanismo vari√°vel conforme dose e via de exposi√ß√£o.",
            "conduct": [
                "Avalia√ß√£o ABCDE e estabiliza√ß√£o inicial",
                "Acesso venoso calibroso + hidrata√ß√£o",
                "Monitoriza√ß√£o: ECG cont√≠nuo, PA, FC, SatO2",
                "Considerar descontamina√ß√£o GI se indicado",
                "Exames: gasometria, eletr√≥litos, fun√ß√£o renal/hep√°tica",
                "Ant√≠doto espec√≠fico se dispon√≠vel",
                "Contato com Centro de Toxicologia: 0800 722 6001"
            ],
            "protocol": f"**MANEJO TOXICOL√ìGICO - {substance.upper()}**\n\n**AVALIA√á√ÉO INICIAL:**\n- ABCDE completo\n- Via a√©rea p√©rvia, suporte ventilat√≥rio se necess√°rio\n- Acesso venoso e estabiliza√ß√£o hemodin√¢mica\n\n**DESCONTAMINA√á√ÉO:**\n- Avaliar tempo de exposi√ß√£o e via\n- Carv√£o ativado 1g/kg se < 1-2h e subst√¢ncia adsorv√≠vel\n- Lavagem g√°strica em casos selecionados\n\n**ANT√çDOTO/TRATAMENTO ESPEC√çFICO:**\n- Verificar disponibilidade de ant√≠doto\n- Consultar Centro de Toxicologia para orienta√ß√£o\n\n**SUPORTE:**\n- Hidrata√ß√£o adequada\n- Corre√ß√£o de dist√∫rbios √°cido-base e eletrol√≠ticos\n- Monitoriza√ß√£o intensiva\n\n**Centro de Informa√ß√µes Toxicol√≥gicas: 0800 722 6001**"
        }
